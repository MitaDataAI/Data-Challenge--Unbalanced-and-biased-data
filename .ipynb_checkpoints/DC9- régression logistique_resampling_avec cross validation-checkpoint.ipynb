{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a653034",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547820e",
   "metadata": {},
   "source": [
    "Lorsqu'on applique la régression logistique sur les données resampling et en faisant le cross validation, le modèle s'est détérioré avec C = 0.001. Pour éviter de trop pénalisé, on a donc réduit C à 0.1 comme l'on a fait auparavant. Ainsi, on a pu avoir une excellente performance. Pourquoi avec un même réglage, l'entrainement avec les données resampling s'en sort très bien par rapport au modèle entrainé aux données brutes? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f424f",
   "metadata": {},
   "source": [
    "**Modèle 1: Avec Rééchantillonnage**\n",
    "- Performance:\n",
    "  - Précision (Accuracy): 0.814\n",
    "  - Macro F1 Score: 0.792\n",
    "  - Micro F1 Score: 0.814\n",
    "- Équité:\n",
    "  - TPR_GAP: 0.182\n",
    "  - FPR_GAP: 0.004\n",
    "  - PPR_GAP: 0.005\n",
    "Score Final: 0.805\n",
    "\n",
    "**Modèle 2: Sans Rééchantillonnage**\n",
    "- Performance:\n",
    "  - Précision (Accuracy): 0.785\n",
    "  - Macro F1 Score: 0.720\n",
    "  - Micro F1 Score: 0.785\n",
    "- Équité:\n",
    "  - TPR_GAP: 0.189\n",
    "  - FPR_GAP: 0.008\n",
    "  - PPR_GAP: 0.024\n",
    "Score Final: 0.766"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af9175",
   "metadata": {},
   "source": [
    "**Impact du Rééchantillonnage sur la Performance:**\n",
    "\n",
    "précision et F1 score. Cela suggère que le rééchantillonnage des données pour réduire les biais de genre a pu améliorer la capacité du modèle à généraliser à de nouvelles données\n",
    "\n",
    "Pourquoi?: Le rééchantillonnage équilibre les classes dans les données d'entraînement. C'est crucial quand les classes sont déséquilibrées. Cela évite que le modèle ne privilégie la classe majoritaire, assurant de meilleures performances globales.\n",
    "\n",
    "**Impact du Rééchantillonnage sur l'Équité:**\n",
    "\n",
    "TPR_GAP, FPR_GAP, et PPR_GAP: Le premier modèle a des écarts réduits en TPR_GAP, FPR_GAP et PPR_GAP, montrant une meilleure équité dans les prédictions.\n",
    "Pourquoi ? Le rééchantillonnage vise à éliminer les biais en représentant équitablement toutes les classes. Cela se traduit par des prédictions plus justes, comme en témoigne la réduction des écarts entre les groupes en TPR et FPR.\n",
    "\n",
    "\n",
    "Le premier modèle, utilisant des données rééchantillonnées pour atténuer la relation entre le genre et la variable cible, est à la fois plus performant et plus équitable. L'amélioration de la performance est due à une meilleure généralisation grâce à des données d'entraînement équilibrées. De même, l'équité est améliorée en minimisant les biais potentiels dans les données d'entraînement, permettant des prédictions plus justes, indépendamment du genre. En résumé, le rééchantillonnage a un impact significativement positif sur la performance et l'équité du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d6d1d6",
   "metadata": {},
   "source": [
    "Cela ne veut pas dire que l'hyperparamètre est à son niveau optimal. Ainsi, on a essayé de simuler la régression logistique avec différents valeurs de C proches de 0.1. On a fait varier dans l'interval supérieur et inférieur tout en restant attentif à l'volution des résultats sur l'entrainement et le test final. Il nous paraît que C = 0.9 engendre une meilleure généralisation et performance dans l'ensemble : \n",
    "\n",
    "(LogisticRegression(C=0.09, max_iter=5000, multi_class='multinomial',\n",
    "                    random_state=42),\n",
    " {'performance_metrics': {'Accuracy': 0.8126801152737753,\n",
    "   'Macro F1 Score': 0.7888312053403073,\n",
    "   'Micro F1 Score': 0.8126801152737753},\n",
    "  'fairness_metrics': {'TPR_GAP': 0.17383415524618148,\n",
    "   'FPR_GAP': 0.003952200171387337,\n",
    "   'PPR_GAP': 0.004325430259110213},\n",
    "  'final_score': 0.8074985250470629,\n",
    "  'number_of_estimators': 'N/A'}).\n",
    "  \n",
    " Avec ce modèle le score sur le test va jusqu'à 78,20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5b88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from modelization import *\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from evaluator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06843cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data-challenge-student.pickle', 'rb') as handle:\n",
    "    # dat = pickle.load(handle)\n",
    "    dat = pd.read_pickle(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd2e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = dat['X_train']\n",
    "\n",
    "# Données à prédire\n",
    "Y_train = dat['Y']\n",
    "\n",
    "# Attributs sensibles\n",
    "S_train = dat['S_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67831ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = dat['X_test'] \n",
    "S_test = dat['S_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b76dbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Supposons que X_train, Y_train, et S_train sont déjà définis comme dans votre question\n",
    "data = pd.concat([S_train, X_train, Y_train],axis=1)\n",
    "\n",
    "balanced_data_list = []\n",
    "for nbclass in range(28):  # Assumant 28 classes professionnelles distinctes\n",
    "    # Sélection des données pour une classe professionnelle spécifique\n",
    "    data_class = data[data['profession_class'] == nbclass]\n",
    "    \n",
    "    # Séparation basée sur la classe de genre\n",
    "    data_s0 = data_class[data_class['gender_class'] == 0]\n",
    "    data_s1 = data_class[data_class['gender_class'] == 1]\n",
    "    \n",
    "    if len(data_s0) >= len(data_s1):\n",
    "        # Rééchantillonnage pour équilibrer les classes de genre\n",
    "        data_s1_resampled = resample(data_s1, replace=True, n_samples=len(data_s0), random_state=42)\n",
    "        balanced_data = pd.concat([data_s0, data_s1_resampled])\n",
    "    else:\n",
    "        data_s0_resampled = resample(data_s0, replace=True, n_samples=len(data_s1), random_state=42)\n",
    "        balanced_data = pd.concat([data_s1, data_s0_resampled])\n",
    "        \n",
    "    balanced_data_list.append(balanced_data)\n",
    "\n",
    "# Combiner toutes les données rééquilibrées en un seul DataFrame\n",
    "balanced_data_combined = pd.concat(balanced_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca4bab6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>profession_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15102</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.106644</td>\n",
       "      <td>0.206202</td>\n",
       "      <td>-0.487275</td>\n",
       "      <td>-0.565128</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.521392</td>\n",
       "      <td>0.222879</td>\n",
       "      <td>0.332393</td>\n",
       "      <td>-0.158473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025967</td>\n",
       "      <td>-0.188476</td>\n",
       "      <td>-0.541974</td>\n",
       "      <td>0.066505</td>\n",
       "      <td>-0.000817</td>\n",
       "      <td>-0.237024</td>\n",
       "      <td>-0.169442</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>0.160571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9853</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.539986</td>\n",
       "      <td>0.367027</td>\n",
       "      <td>-1.042473</td>\n",
       "      <td>-0.315929</td>\n",
       "      <td>0.223228</td>\n",
       "      <td>-0.020717</td>\n",
       "      <td>-0.085954</td>\n",
       "      <td>0.298949</td>\n",
       "      <td>-0.063420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231364</td>\n",
       "      <td>0.026662</td>\n",
       "      <td>-0.298197</td>\n",
       "      <td>0.536527</td>\n",
       "      <td>-0.356383</td>\n",
       "      <td>0.343746</td>\n",
       "      <td>0.356660</td>\n",
       "      <td>0.265317</td>\n",
       "      <td>0.140032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38521</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.667977</td>\n",
       "      <td>0.534055</td>\n",
       "      <td>-0.372200</td>\n",
       "      <td>-0.912800</td>\n",
       "      <td>-0.162027</td>\n",
       "      <td>0.316608</td>\n",
       "      <td>0.409040</td>\n",
       "      <td>0.698239</td>\n",
       "      <td>-0.228332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174538</td>\n",
       "      <td>-0.090482</td>\n",
       "      <td>-0.540254</td>\n",
       "      <td>0.252228</td>\n",
       "      <td>0.325463</td>\n",
       "      <td>-0.212083</td>\n",
       "      <td>0.143992</td>\n",
       "      <td>-0.016629</td>\n",
       "      <td>0.306894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22478</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.646435</td>\n",
       "      <td>0.244130</td>\n",
       "      <td>-0.838173</td>\n",
       "      <td>-0.224850</td>\n",
       "      <td>-0.186924</td>\n",
       "      <td>0.327114</td>\n",
       "      <td>-0.150429</td>\n",
       "      <td>0.745634</td>\n",
       "      <td>-0.238859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076886</td>\n",
       "      <td>0.060196</td>\n",
       "      <td>0.024156</td>\n",
       "      <td>0.312725</td>\n",
       "      <td>0.224630</td>\n",
       "      <td>-0.279840</td>\n",
       "      <td>0.124797</td>\n",
       "      <td>0.418145</td>\n",
       "      <td>0.388695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28294</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.269952</td>\n",
       "      <td>0.055027</td>\n",
       "      <td>-0.498366</td>\n",
       "      <td>-0.789691</td>\n",
       "      <td>0.517833</td>\n",
       "      <td>0.072657</td>\n",
       "      <td>0.168787</td>\n",
       "      <td>0.356092</td>\n",
       "      <td>-0.075094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280233</td>\n",
       "      <td>0.377222</td>\n",
       "      <td>-0.733948</td>\n",
       "      <td>0.610944</td>\n",
       "      <td>-0.117537</td>\n",
       "      <td>-0.160587</td>\n",
       "      <td>0.328925</td>\n",
       "      <td>0.379089</td>\n",
       "      <td>0.035509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.150664</td>\n",
       "      <td>-0.275969</td>\n",
       "      <td>0.328843</td>\n",
       "      <td>-0.289479</td>\n",
       "      <td>-0.359328</td>\n",
       "      <td>-0.589007</td>\n",
       "      <td>0.828748</td>\n",
       "      <td>0.445308</td>\n",
       "      <td>-0.073924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.451324</td>\n",
       "      <td>-0.064055</td>\n",
       "      <td>-0.831989</td>\n",
       "      <td>0.462128</td>\n",
       "      <td>0.823785</td>\n",
       "      <td>-0.522116</td>\n",
       "      <td>-0.273711</td>\n",
       "      <td>-0.010537</td>\n",
       "      <td>0.610961</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.696221</td>\n",
       "      <td>0.049864</td>\n",
       "      <td>-0.205544</td>\n",
       "      <td>-0.244224</td>\n",
       "      <td>-0.378419</td>\n",
       "      <td>-0.132278</td>\n",
       "      <td>0.664804</td>\n",
       "      <td>0.635028</td>\n",
       "      <td>0.081595</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171151</td>\n",
       "      <td>0.397429</td>\n",
       "      <td>-0.452958</td>\n",
       "      <td>0.146219</td>\n",
       "      <td>0.330908</td>\n",
       "      <td>-0.029582</td>\n",
       "      <td>-0.276181</td>\n",
       "      <td>0.445554</td>\n",
       "      <td>-0.012045</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22208</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.071043</td>\n",
       "      <td>0.044882</td>\n",
       "      <td>-0.311584</td>\n",
       "      <td>-0.620255</td>\n",
       "      <td>-0.161639</td>\n",
       "      <td>0.015657</td>\n",
       "      <td>0.541004</td>\n",
       "      <td>0.306950</td>\n",
       "      <td>0.011576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.627619</td>\n",
       "      <td>-0.025529</td>\n",
       "      <td>-0.389166</td>\n",
       "      <td>-0.107837</td>\n",
       "      <td>0.682593</td>\n",
       "      <td>-0.051020</td>\n",
       "      <td>0.044216</td>\n",
       "      <td>0.269877</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22664</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.269814</td>\n",
       "      <td>-0.132485</td>\n",
       "      <td>0.134214</td>\n",
       "      <td>-0.446334</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>-0.351853</td>\n",
       "      <td>0.659138</td>\n",
       "      <td>0.553297</td>\n",
       "      <td>-0.405849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016632</td>\n",
       "      <td>0.678242</td>\n",
       "      <td>-0.739566</td>\n",
       "      <td>0.369372</td>\n",
       "      <td>0.412901</td>\n",
       "      <td>-0.314313</td>\n",
       "      <td>-0.157456</td>\n",
       "      <td>0.622148</td>\n",
       "      <td>-0.006625</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19012</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.459195</td>\n",
       "      <td>-0.109860</td>\n",
       "      <td>-0.494423</td>\n",
       "      <td>-0.681777</td>\n",
       "      <td>-0.361663</td>\n",
       "      <td>0.258196</td>\n",
       "      <td>0.604760</td>\n",
       "      <td>0.530319</td>\n",
       "      <td>-0.050006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.367545</td>\n",
       "      <td>0.362914</td>\n",
       "      <td>-0.585649</td>\n",
       "      <td>0.072264</td>\n",
       "      <td>0.290634</td>\n",
       "      <td>0.046252</td>\n",
       "      <td>0.202949</td>\n",
       "      <td>0.636003</td>\n",
       "      <td>-0.037533</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34704 rows × 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender_class         0         1         2         3         4  \\\n",
       "15102             0 -0.106644  0.206202 -0.487275 -0.565128  0.002457   \n",
       "9853              0 -0.539986  0.367027 -1.042473 -0.315929  0.223228   \n",
       "38521             0 -0.667977  0.534055 -0.372200 -0.912800 -0.162027   \n",
       "22478             0 -0.646435  0.244130 -0.838173 -0.224850 -0.186924   \n",
       "28294             0 -0.269952  0.055027 -0.498366 -0.789691  0.517833   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "4076              0 -0.150664 -0.275969  0.328843 -0.289479 -0.359328   \n",
       "4712              0 -0.696221  0.049864 -0.205544 -0.244224 -0.378419   \n",
       "22208             0 -0.071043  0.044882 -0.311584 -0.620255 -0.161639   \n",
       "22664             0 -0.269814 -0.132485  0.134214 -0.446334 -0.440597   \n",
       "19012             0 -0.459195 -0.109860 -0.494423 -0.681777 -0.361663   \n",
       "\n",
       "              5         6         7         8  ...       759       760  \\\n",
       "15102  0.521392  0.222879  0.332393 -0.158473  ... -0.025967 -0.188476   \n",
       "9853  -0.020717 -0.085954  0.298949 -0.063420  ... -0.231364  0.026662   \n",
       "38521  0.316608  0.409040  0.698239 -0.228332  ... -0.174538 -0.090482   \n",
       "22478  0.327114 -0.150429  0.745634 -0.238859  ... -0.076886  0.060196   \n",
       "28294  0.072657  0.168787  0.356092 -0.075094  ... -0.280233  0.377222   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "4076  -0.589007  0.828748  0.445308 -0.073924  ... -0.451324 -0.064055   \n",
       "4712  -0.132278  0.664804  0.635028  0.081595  ... -0.171151  0.397429   \n",
       "22208  0.015657  0.541004  0.306950  0.011576  ... -0.627619 -0.025529   \n",
       "22664 -0.351853  0.659138  0.553297 -0.405849  ...  0.016632  0.678242   \n",
       "19012  0.258196  0.604760  0.530319 -0.050006  ... -0.367545  0.362914   \n",
       "\n",
       "            761       762       763       764       765       766       767  \\\n",
       "15102 -0.541974  0.066505 -0.000817 -0.237024 -0.169442  0.153728  0.160571   \n",
       "9853  -0.298197  0.536527 -0.356383  0.343746  0.356660  0.265317  0.140032   \n",
       "38521 -0.540254  0.252228  0.325463 -0.212083  0.143992 -0.016629  0.306894   \n",
       "22478  0.024156  0.312725  0.224630 -0.279840  0.124797  0.418145  0.388695   \n",
       "28294 -0.733948  0.610944 -0.117537 -0.160587  0.328925  0.379089  0.035509   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "4076  -0.831989  0.462128  0.823785 -0.522116 -0.273711 -0.010537  0.610961   \n",
       "4712  -0.452958  0.146219  0.330908 -0.029582 -0.276181  0.445554 -0.012045   \n",
       "22208 -0.389166 -0.107837  0.682593 -0.051020  0.044216  0.269877  0.008501   \n",
       "22664 -0.739566  0.369372  0.412901 -0.314313 -0.157456  0.622148 -0.006625   \n",
       "19012 -0.585649  0.072264  0.290634  0.046252  0.202949  0.636003 -0.037533   \n",
       "\n",
       "       profession_class  \n",
       "15102                 0  \n",
       "9853                  0  \n",
       "38521                 0  \n",
       "22478                 0  \n",
       "28294                 0  \n",
       "...                 ...  \n",
       "4076                 27  \n",
       "4712                 27  \n",
       "22208                27  \n",
       "22664                27  \n",
       "19012                27  \n",
       "\n",
       "[34704 rows x 770 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb8ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ae8aa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming balanced_data_combined is a pandas DataFrame\n",
    "# Supprimer la première colonne\n",
    "X_balanced = balanced_data_combined.iloc[:, 1:]\n",
    "\n",
    "# Supprimer la dernière colonne\n",
    "X_balanced = X_balanced.iloc[:, :-1]\n",
    "\n",
    "S_balanced = balanced_data_combined.iloc[:, 0]\n",
    "\n",
    "Y_balanced = balanced_data_combined.iloc[:, -1]  # Select all rows for the second-last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebe8dd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15102</th>\n",
       "      <td>-0.106644</td>\n",
       "      <td>0.206202</td>\n",
       "      <td>-0.487275</td>\n",
       "      <td>-0.565128</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.521392</td>\n",
       "      <td>0.222879</td>\n",
       "      <td>0.332393</td>\n",
       "      <td>-0.158473</td>\n",
       "      <td>-0.425709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262542</td>\n",
       "      <td>-0.025967</td>\n",
       "      <td>-0.188476</td>\n",
       "      <td>-0.541974</td>\n",
       "      <td>0.066505</td>\n",
       "      <td>-0.000817</td>\n",
       "      <td>-0.237024</td>\n",
       "      <td>-0.169442</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>0.160571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9853</th>\n",
       "      <td>-0.539986</td>\n",
       "      <td>0.367027</td>\n",
       "      <td>-1.042473</td>\n",
       "      <td>-0.315929</td>\n",
       "      <td>0.223228</td>\n",
       "      <td>-0.020717</td>\n",
       "      <td>-0.085954</td>\n",
       "      <td>0.298949</td>\n",
       "      <td>-0.063420</td>\n",
       "      <td>-0.127194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263436</td>\n",
       "      <td>-0.231364</td>\n",
       "      <td>0.026662</td>\n",
       "      <td>-0.298197</td>\n",
       "      <td>0.536527</td>\n",
       "      <td>-0.356383</td>\n",
       "      <td>0.343746</td>\n",
       "      <td>0.356660</td>\n",
       "      <td>0.265317</td>\n",
       "      <td>0.140032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38521</th>\n",
       "      <td>-0.667977</td>\n",
       "      <td>0.534055</td>\n",
       "      <td>-0.372200</td>\n",
       "      <td>-0.912800</td>\n",
       "      <td>-0.162027</td>\n",
       "      <td>0.316608</td>\n",
       "      <td>0.409040</td>\n",
       "      <td>0.698239</td>\n",
       "      <td>-0.228332</td>\n",
       "      <td>0.177368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074018</td>\n",
       "      <td>-0.174538</td>\n",
       "      <td>-0.090482</td>\n",
       "      <td>-0.540254</td>\n",
       "      <td>0.252228</td>\n",
       "      <td>0.325463</td>\n",
       "      <td>-0.212083</td>\n",
       "      <td>0.143992</td>\n",
       "      <td>-0.016629</td>\n",
       "      <td>0.306894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22478</th>\n",
       "      <td>-0.646435</td>\n",
       "      <td>0.244130</td>\n",
       "      <td>-0.838173</td>\n",
       "      <td>-0.224850</td>\n",
       "      <td>-0.186924</td>\n",
       "      <td>0.327114</td>\n",
       "      <td>-0.150429</td>\n",
       "      <td>0.745634</td>\n",
       "      <td>-0.238859</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040561</td>\n",
       "      <td>-0.076886</td>\n",
       "      <td>0.060196</td>\n",
       "      <td>0.024156</td>\n",
       "      <td>0.312725</td>\n",
       "      <td>0.224630</td>\n",
       "      <td>-0.279840</td>\n",
       "      <td>0.124797</td>\n",
       "      <td>0.418145</td>\n",
       "      <td>0.388695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28294</th>\n",
       "      <td>-0.269952</td>\n",
       "      <td>0.055027</td>\n",
       "      <td>-0.498366</td>\n",
       "      <td>-0.789691</td>\n",
       "      <td>0.517833</td>\n",
       "      <td>0.072657</td>\n",
       "      <td>0.168787</td>\n",
       "      <td>0.356092</td>\n",
       "      <td>-0.075094</td>\n",
       "      <td>-0.683792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199538</td>\n",
       "      <td>-0.280233</td>\n",
       "      <td>0.377222</td>\n",
       "      <td>-0.733948</td>\n",
       "      <td>0.610944</td>\n",
       "      <td>-0.117537</td>\n",
       "      <td>-0.160587</td>\n",
       "      <td>0.328925</td>\n",
       "      <td>0.379089</td>\n",
       "      <td>0.035509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>-0.150664</td>\n",
       "      <td>-0.275969</td>\n",
       "      <td>0.328843</td>\n",
       "      <td>-0.289479</td>\n",
       "      <td>-0.359328</td>\n",
       "      <td>-0.589007</td>\n",
       "      <td>0.828748</td>\n",
       "      <td>0.445308</td>\n",
       "      <td>-0.073924</td>\n",
       "      <td>-0.626374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219889</td>\n",
       "      <td>-0.451324</td>\n",
       "      <td>-0.064055</td>\n",
       "      <td>-0.831989</td>\n",
       "      <td>0.462128</td>\n",
       "      <td>0.823785</td>\n",
       "      <td>-0.522116</td>\n",
       "      <td>-0.273711</td>\n",
       "      <td>-0.010537</td>\n",
       "      <td>0.610961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>-0.696221</td>\n",
       "      <td>0.049864</td>\n",
       "      <td>-0.205544</td>\n",
       "      <td>-0.244224</td>\n",
       "      <td>-0.378419</td>\n",
       "      <td>-0.132278</td>\n",
       "      <td>0.664804</td>\n",
       "      <td>0.635028</td>\n",
       "      <td>0.081595</td>\n",
       "      <td>-0.573454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.403174</td>\n",
       "      <td>-0.171151</td>\n",
       "      <td>0.397429</td>\n",
       "      <td>-0.452958</td>\n",
       "      <td>0.146219</td>\n",
       "      <td>0.330908</td>\n",
       "      <td>-0.029582</td>\n",
       "      <td>-0.276181</td>\n",
       "      <td>0.445554</td>\n",
       "      <td>-0.012045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22208</th>\n",
       "      <td>-0.071043</td>\n",
       "      <td>0.044882</td>\n",
       "      <td>-0.311584</td>\n",
       "      <td>-0.620255</td>\n",
       "      <td>-0.161639</td>\n",
       "      <td>0.015657</td>\n",
       "      <td>0.541004</td>\n",
       "      <td>0.306950</td>\n",
       "      <td>0.011576</td>\n",
       "      <td>-0.167356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098436</td>\n",
       "      <td>-0.627619</td>\n",
       "      <td>-0.025529</td>\n",
       "      <td>-0.389166</td>\n",
       "      <td>-0.107837</td>\n",
       "      <td>0.682593</td>\n",
       "      <td>-0.051020</td>\n",
       "      <td>0.044216</td>\n",
       "      <td>0.269877</td>\n",
       "      <td>0.008501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22664</th>\n",
       "      <td>-0.269814</td>\n",
       "      <td>-0.132485</td>\n",
       "      <td>0.134214</td>\n",
       "      <td>-0.446334</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>-0.351853</td>\n",
       "      <td>0.659138</td>\n",
       "      <td>0.553297</td>\n",
       "      <td>-0.405849</td>\n",
       "      <td>-0.363420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137180</td>\n",
       "      <td>0.016632</td>\n",
       "      <td>0.678242</td>\n",
       "      <td>-0.739566</td>\n",
       "      <td>0.369372</td>\n",
       "      <td>0.412901</td>\n",
       "      <td>-0.314313</td>\n",
       "      <td>-0.157456</td>\n",
       "      <td>0.622148</td>\n",
       "      <td>-0.006625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19012</th>\n",
       "      <td>-0.459195</td>\n",
       "      <td>-0.109860</td>\n",
       "      <td>-0.494423</td>\n",
       "      <td>-0.681777</td>\n",
       "      <td>-0.361663</td>\n",
       "      <td>0.258196</td>\n",
       "      <td>0.604760</td>\n",
       "      <td>0.530319</td>\n",
       "      <td>-0.050006</td>\n",
       "      <td>-0.425231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026994</td>\n",
       "      <td>-0.367545</td>\n",
       "      <td>0.362914</td>\n",
       "      <td>-0.585649</td>\n",
       "      <td>0.072264</td>\n",
       "      <td>0.290634</td>\n",
       "      <td>0.046252</td>\n",
       "      <td>0.202949</td>\n",
       "      <td>0.636003</td>\n",
       "      <td>-0.037533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34704 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "15102 -0.106644  0.206202 -0.487275 -0.565128  0.002457  0.521392  0.222879   \n",
       "9853  -0.539986  0.367027 -1.042473 -0.315929  0.223228 -0.020717 -0.085954   \n",
       "38521 -0.667977  0.534055 -0.372200 -0.912800 -0.162027  0.316608  0.409040   \n",
       "22478 -0.646435  0.244130 -0.838173 -0.224850 -0.186924  0.327114 -0.150429   \n",
       "28294 -0.269952  0.055027 -0.498366 -0.789691  0.517833  0.072657  0.168787   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "4076  -0.150664 -0.275969  0.328843 -0.289479 -0.359328 -0.589007  0.828748   \n",
       "4712  -0.696221  0.049864 -0.205544 -0.244224 -0.378419 -0.132278  0.664804   \n",
       "22208 -0.071043  0.044882 -0.311584 -0.620255 -0.161639  0.015657  0.541004   \n",
       "22664 -0.269814 -0.132485  0.134214 -0.446334 -0.440597 -0.351853  0.659138   \n",
       "19012 -0.459195 -0.109860 -0.494423 -0.681777 -0.361663  0.258196  0.604760   \n",
       "\n",
       "            7         8         9    ...       758       759       760  \\\n",
       "15102  0.332393 -0.158473 -0.425709  ...  0.262542 -0.025967 -0.188476   \n",
       "9853   0.298949 -0.063420 -0.127194  ...  0.263436 -0.231364  0.026662   \n",
       "38521  0.698239 -0.228332  0.177368  ...  0.074018 -0.174538 -0.090482   \n",
       "22478  0.745634 -0.238859  0.379400  ...  0.040561 -0.076886  0.060196   \n",
       "28294  0.356092 -0.075094 -0.683792  ...  0.199538 -0.280233  0.377222   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "4076   0.445308 -0.073924 -0.626374  ...  0.219889 -0.451324 -0.064055   \n",
       "4712   0.635028  0.081595 -0.573454  ... -0.403174 -0.171151  0.397429   \n",
       "22208  0.306950  0.011576 -0.167356  ...  0.098436 -0.627619 -0.025529   \n",
       "22664  0.553297 -0.405849 -0.363420  ... -0.137180  0.016632  0.678242   \n",
       "19012  0.530319 -0.050006 -0.425231  ... -0.026994 -0.367545  0.362914   \n",
       "\n",
       "            761       762       763       764       765       766       767  \n",
       "15102 -0.541974  0.066505 -0.000817 -0.237024 -0.169442  0.153728  0.160571  \n",
       "9853  -0.298197  0.536527 -0.356383  0.343746  0.356660  0.265317  0.140032  \n",
       "38521 -0.540254  0.252228  0.325463 -0.212083  0.143992 -0.016629  0.306894  \n",
       "22478  0.024156  0.312725  0.224630 -0.279840  0.124797  0.418145  0.388695  \n",
       "28294 -0.733948  0.610944 -0.117537 -0.160587  0.328925  0.379089  0.035509  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "4076  -0.831989  0.462128  0.823785 -0.522116 -0.273711 -0.010537  0.610961  \n",
       "4712  -0.452958  0.146219  0.330908 -0.029582 -0.276181  0.445554 -0.012045  \n",
       "22208 -0.389166 -0.107837  0.682593 -0.051020  0.044216  0.269877  0.008501  \n",
       "22664 -0.739566  0.369372  0.412901 -0.314313 -0.157456  0.622148 -0.006625  \n",
       "19012 -0.585649  0.072264  0.290634  0.046252  0.202949  0.636003 -0.037533  \n",
       "\n",
       "[34704 rows x 768 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3a75fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15102    0\n",
       "9853     0\n",
       "38521    0\n",
       "22478    0\n",
       "28294    0\n",
       "        ..\n",
       "4076     0\n",
       "4712     0\n",
       "22208    0\n",
       "22664    0\n",
       "19012    0\n",
       "Name: gender_class, Length: 34704, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbca6690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15102     0\n",
       "9853      0\n",
       "38521     0\n",
       "22478     0\n",
       "28294     0\n",
       "         ..\n",
       "4076     27\n",
       "4712     27\n",
       "22208    27\n",
       "22664    27\n",
       "19012    27\n",
       "Name: profession_class, Length: 34704, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7e3842",
   "metadata": {},
   "source": [
    "# modèle avec C=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17e48d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Configuration de la validation croisée\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Initialisation du modèle avec les paramètres spécifiques\n",
    "model_1 = LogisticRegression(random_state=42, solver='lbfgs', C=0.001, multi_class='multinomial', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7de3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = train_and_evaluate(model_1, X_balanced, Y_balanced, S_balanced, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c125da09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.001, max_iter=5000, multi_class='multinomial'),\n",
       " {'performance_metrics': {'Accuracy': 0.6646499567847882,\n",
       "   'Macro F1 Score': 0.4120925272854986,\n",
       "   'Micro F1 Score': 0.6646499567847882},\n",
       "  'fairness_metrics': {'TPR_GAP': 0.10299692310266696,\n",
       "   'FPR_GAP': 0.008388676021826632,\n",
       "   'PPR_GAP': 0.008886545606355751},\n",
       "  'final_score': 0.6545478020914158,\n",
       "  'number_of_estimators': 'N/A'})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6844b8f5",
   "metadata": {},
   "source": [
    "# modèle avec C=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "104300b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Configuration de la validation croisée\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Initialisation du modèle avec les paramètres spécifiques\n",
    "model_2 = LogisticRegression(random_state=42, solver='lbfgs', C=0.1, multi_class='multinomial', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f741cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2 = train_and_evaluate(model_2, X_balanced, Y_balanced, S_balanced, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14ca4d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.1, max_iter=5000, multi_class='multinomial',\n",
       "                    random_state=42),\n",
       " {'performance_metrics': {'Accuracy': 0.8141210374639769,\n",
       "   'Macro F1 Score': 0.7916262462858562,\n",
       "   'Micro F1 Score': 0.8141210374639769},\n",
       "  'fairness_metrics': {'TPR_GAP': 0.18156604252832018,\n",
       "   'FPR_GAP': 0.004012551187902068,\n",
       "   'PPR_GAP': 0.004524875067262163},\n",
       "  'final_score': 0.805030101878768,\n",
       "  'number_of_estimators': 'N/A'})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68eb4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_classique = result_2[0].predict(X_test.values)\n",
    "results=pd.DataFrame(regression_classique, columns= ['score'])\n",
    "\n",
    "results.to_csv(\"Data_Challenge_MDI_c01.csv\", header = None,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4581b2",
   "metadata": {},
   "source": [
    "# modèle avec C 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d363658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Configuration de la validation croisée\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Initialisation du modèle avec les paramètres spécifiques\n",
    "model_3 = LogisticRegression(random_state=42, solver='lbfgs', C=0.2, multi_class='multinomial', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4d2f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3 = train_and_evaluate(model_3, X_balanced, Y_balanced, S_balanced, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a3eb4e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.2, max_iter=5000, multi_class='multinomial',\n",
       "                    random_state=42),\n",
       " {'performance_metrics': {'Accuracy': 0.8193083573487032,\n",
       "   'Macro F1 Score': 0.8037774064068582,\n",
       "   'Micro F1 Score': 0.8193083573487032},\n",
       "  'fairness_metrics': {'TPR_GAP': 0.23596706886173952,\n",
       "   'FPR_GAP': 0.003611114369412836,\n",
       "   'PPR_GAP': 0.00434063616888848},\n",
       "  'final_score': 0.7839051687725593,\n",
       "  'number_of_estimators': 'N/A'})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "382412da",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_classique = result_3[0].predict(X_test.values)\n",
    "results=pd.DataFrame(regression_classique, columns= ['score'])\n",
    "\n",
    "results.to_csv(\"Data_Challenge_MDI_c02.csv\", header = None,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e775681",
   "metadata": {},
   "source": [
    "# modèle avec C 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0322dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Configuration de la validation croisée\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Initialisation du modèle avec les paramètres spécifiques\n",
    "model_4 = LogisticRegression(random_state=42, solver='lbfgs', C=0.5, multi_class='multinomial', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12674214",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_4 = train_and_evaluate(model_4, X_balanced, Y_balanced, S_balanced, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6cbea5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.5, max_iter=5000, multi_class='multinomial',\n",
       "                    random_state=42),\n",
       " {'performance_metrics': {'Accuracy': 0.822241428983002,\n",
       "   'Macro F1 Score': 0.7973501815489147,\n",
       "   'Micro F1 Score': 0.822241428983002},\n",
       "  'fairness_metrics': {'TPR_GAP': 0.23168778050990602,\n",
       "   'FPR_GAP': 0.004773274089815812,\n",
       "   'PPR_GAP': 0.00517583851036082},\n",
       "  'final_score': 0.7828312005195044,\n",
       "  'number_of_estimators': 'N/A'})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78e57843",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_classique = result_4[0].predict(X_test.values)\n",
    "results=pd.DataFrame(regression_classique, columns= ['score'])\n",
    "\n",
    "results.to_csv(\"Data_Challenge_MDI_c05.csv\", header = None,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d91eec5",
   "metadata": {},
   "source": [
    "# modèle avec C 0.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a912ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Configuration de la validation croisée\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Initialisation du modèle avec les paramètres spécifiques\n",
    "model_5 = LogisticRegression(random_state=42, solver='lbfgs', C=0.09, multi_class='multinomial', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "23d0f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_5 = train_and_evaluate(model_5, X_balanced, Y_balanced, S_balanced, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a61411bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.09, max_iter=5000, multi_class='multinomial',\n",
       "                    random_state=42),\n",
       " {'performance_metrics': {'Accuracy': 0.8126801152737753,\n",
       "   'Macro F1 Score': 0.7888312053403073,\n",
       "   'Micro F1 Score': 0.8126801152737753},\n",
       "  'fairness_metrics': {'TPR_GAP': 0.17383415524618148,\n",
       "   'FPR_GAP': 0.003952200171387337,\n",
       "   'PPR_GAP': 0.004325430259110213},\n",
       "  'final_score': 0.8074985250470629,\n",
       "  'number_of_estimators': 'N/A'})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3e6c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_classique = result_5[0].predict(X_test.values)\n",
    "results=pd.DataFrame(regression_classique, columns= ['score'])\n",
    "\n",
    "results.to_csv(\"Data_Challenge_MDI_c1.csv\", header = None,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d216e2",
   "metadata": {},
   "source": [
    "# modèle avec C 0.092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e1fae255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Configuration de la validation croisée\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Initialisation du modèle avec les paramètres spécifiques\n",
    "model_6 = LogisticRegression(random_state=42, solver='lbfgs', C=0.092, multi_class='multinomial', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2a807cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_6 = train_and_evaluate(model_6, X_balanced, Y_balanced, S_balanced, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cbc21a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.092, max_iter=5000, multi_class='multinomial',\n",
       "                    random_state=42),\n",
       " {'performance_metrics': {'Accuracy': 0.8126801152737753,\n",
       "   'Macro F1 Score': 0.7879424010677223,\n",
       "   'Micro F1 Score': 0.8126801152737753},\n",
       "  'fairness_metrics': {'TPR_GAP': 0.17352185485139063,\n",
       "   'FPR_GAP': 0.003939873608294418,\n",
       "   'PPR_GAP': 0.0043376700880842604},\n",
       "  'final_score': 0.8072102731081658,\n",
       "  'number_of_estimators': 'N/A'})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adbd02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_classique = result_6[0].predict(X_test.values)\n",
    "results=pd.DataFrame(regression_classique, columns= ['score'])\n",
    "\n",
    "results.to_csv(\"Data_Challenge_MDI_c092.csv\", header = None,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22507a50",
   "metadata": {},
   "source": [
    "# modèle avec C 0.094"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "26246da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Configuration de la validation croisée\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Initialisation du modèle avec les paramètres spécifiques\n",
    "model_7 = LogisticRegression(random_state=42, solver='lbfgs', C=0.094, multi_class='multinomial', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "820f8de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_7 = train_and_evaluate(model_7, X_balanced, Y_balanced, S_balanced, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d19bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_classique = result_7[0].predict(X_test.values)\n",
    "results=pd.DataFrame(regression_classique, columns= ['score'])\n",
    "\n",
    "results.to_csv(\"Data_Challenge_MDI_c094.csv\", header = None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f0c4ce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.094, max_iter=5000, multi_class='multinomial',\n",
       "                    random_state=42),\n",
       " {'performance_metrics': {'Accuracy': 0.8129682997118156,\n",
       "   'Macro F1 Score': 0.7897626518746941,\n",
       "   'Micro F1 Score': 0.8129682997118156},\n",
       "  'fairness_metrics': {'TPR_GAP': 0.1825012241152687,\n",
       "   'FPR_GAP': 0.0038970581967480095,\n",
       "   'PPR_GAP': 0.004351441681491001},\n",
       "  'final_score': 0.8036307138797127,\n",
       "  'number_of_estimators': 'N/A'})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea347b2",
   "metadata": {},
   "source": [
    "# modèle avec C 0.089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9e83b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Configuration de la validation croisée\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Initialisation du modèle avec les paramètres spécifiques\n",
    "model_8 = LogisticRegression(random_state=42, solver='lbfgs', C=0.089, multi_class='multinomial', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2eea50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_8 = train_and_evaluate(model_8, X_balanced, Y_balanced, S_balanced, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98591a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.089, max_iter=5000, multi_class='multinomial',\n",
       "                    random_state=42),\n",
       " {'performance_metrics': {'Accuracy': 0.8121037463976946,\n",
       "   'Macro F1 Score': 0.7882220258809245,\n",
       "   'Micro F1 Score': 0.8121037463976946},\n",
       "  'fairness_metrics': {'TPR_GAP': 0.1739350021392385,\n",
       "   'FPR_GAP': 0.0037898193533557846,\n",
       "   'PPR_GAP': 0.004186467978556214},\n",
       "  'final_score': 0.807143511870843,\n",
       "  'number_of_estimators': 'N/A'})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_classique = result_8[0].predict(X_test.values)\n",
    "results=pd.DataFrame(regression_classique, columns= ['score'])\n",
    "\n",
    "results.to_csv(\"Data_Challenge_MDI_c096.csv\", header = None,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0822b52",
   "metadata": {},
   "source": [
    "# modèle avec C 0.085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d893194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Configuration de la validation croisée\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Initialisation du modèle avec les paramètres spécifiques\n",
    "model_9 = LogisticRegression(random_state=42, solver='lbfgs', C=0.085, multi_class='multinomial', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3638cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_9 = train_and_evaluate(model_9, X_balanced, Y_balanced, S_balanced, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b117a28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.085, max_iter=5000, multi_class='multinomial',\n",
       "                    random_state=42),\n",
       " {'performance_metrics': {'Accuracy': 0.8106628242074928,\n",
       "   'Macro F1 Score': 0.7865837881329135,\n",
       "   'Micro F1 Score': 0.8106628242074928},\n",
       "  'fairness_metrics': {'TPR_GAP': 0.171479220863163,\n",
       "   'FPR_GAP': 0.0037942737037841927,\n",
       "   'PPR_GAP': 0.004140113341055508},\n",
       "  'final_score': 0.8075522836348752,\n",
       "  'number_of_estimators': 'N/A'})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29021fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_classique = result_9[0].predict(X_test.values)\n",
    "results=pd.DataFrame(regression_classique, columns= ['score'])\n",
    "\n",
    "results.to_csv(\"Data_Challenge_MDI_c098.csv\", header = None,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2696867",
   "metadata": {},
   "source": [
    "# modèle avec C 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Configuration de la validation croisée\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Initialisation du modèle avec les paramètres spécifiques\n",
    "model_10 = LogisticRegression(random_state=42, solver='lbfgs', C=0.08, multi_class='multinomial', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_10 = train_and_evaluate(model_10, X_balanced, Y_balanced, S_balanced, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "422487eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result_10\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result_10' is not defined"
     ]
    }
   ],
   "source": [
    "result_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_classique = result_10[0].predict(X_test.values)\n",
    "results=pd.DataFrame(regression_classique, columns= ['score'])\n",
    "\n",
    "results.to_csv(\"Data_Challenge_MDI_c099.csv\", header = None,index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
