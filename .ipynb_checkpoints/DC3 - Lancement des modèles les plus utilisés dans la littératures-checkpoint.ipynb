{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68454199",
   "metadata": {},
   "source": [
    "# Conclusion dans ce chapitre "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87d2e7",
   "metadata": {},
   "source": [
    "Les modèles qui performent le mieux sont : \n",
    "- régression logistique\n",
    "- SVM \n",
    "- SGD Classifier.\n",
    "\n",
    "Parmis ces trois, voici l'ordre de la rapidité : \n",
    "- SGD Classifier.\n",
    "- régression logistique\n",
    "- SVM\n",
    "\n",
    "SVM est un modèle qui ne s'adapte pas à une grande quantité d'observations par rapport à la variable. Quant on a fait une répartition 80-20 des données, SVM a moins de pouvoir prédictif que 70-30.\n",
    "\n",
    "Etant donné un modèle sensible aux unités, nous allons essayer SVM dans les données standartisées. Peut-être qu'il va faire mieux dans ce cadre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7bc9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from evaluator import *\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a586589",
   "metadata": {},
   "source": [
    "# Importer données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbc35899",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('df_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a45aa5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, :768]\n",
    "Y_train = df_train.iloc[:, 768]\n",
    "gender_train = df_train.iloc[:, 769]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aa4754b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.060026</td>\n",
       "      <td>0.221741</td>\n",
       "      <td>-0.433798</td>\n",
       "      <td>-0.083594</td>\n",
       "      <td>-0.168791</td>\n",
       "      <td>-0.329348</td>\n",
       "      <td>0.331437</td>\n",
       "      <td>0.270058</td>\n",
       "      <td>0.051187</td>\n",
       "      <td>-0.362599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095292</td>\n",
       "      <td>-0.303023</td>\n",
       "      <td>0.074494</td>\n",
       "      <td>-0.489258</td>\n",
       "      <td>-0.217383</td>\n",
       "      <td>0.375361</td>\n",
       "      <td>-0.074646</td>\n",
       "      <td>-0.213903</td>\n",
       "      <td>0.598430</td>\n",
       "      <td>-0.047500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417709</td>\n",
       "      <td>0.230312</td>\n",
       "      <td>-0.006228</td>\n",
       "      <td>-0.393662</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>-0.102744</td>\n",
       "      <td>0.424900</td>\n",
       "      <td>0.378988</td>\n",
       "      <td>0.259314</td>\n",
       "      <td>-0.420153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043257</td>\n",
       "      <td>-0.230388</td>\n",
       "      <td>0.594411</td>\n",
       "      <td>-0.459798</td>\n",
       "      <td>0.150881</td>\n",
       "      <td>0.059332</td>\n",
       "      <td>-0.446885</td>\n",
       "      <td>-0.145089</td>\n",
       "      <td>0.407795</td>\n",
       "      <td>0.438078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.283884</td>\n",
       "      <td>0.192580</td>\n",
       "      <td>-0.870445</td>\n",
       "      <td>-0.476400</td>\n",
       "      <td>-0.394105</td>\n",
       "      <td>0.354576</td>\n",
       "      <td>-0.109303</td>\n",
       "      <td>-0.130869</td>\n",
       "      <td>0.137070</td>\n",
       "      <td>-0.577601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077262</td>\n",
       "      <td>-0.424112</td>\n",
       "      <td>0.123815</td>\n",
       "      <td>-0.916357</td>\n",
       "      <td>0.021797</td>\n",
       "      <td>0.347901</td>\n",
       "      <td>-0.310322</td>\n",
       "      <td>-0.152313</td>\n",
       "      <td>0.018452</td>\n",
       "      <td>0.146952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.359992</td>\n",
       "      <td>0.444496</td>\n",
       "      <td>-0.386753</td>\n",
       "      <td>-0.415471</td>\n",
       "      <td>-0.221740</td>\n",
       "      <td>0.355020</td>\n",
       "      <td>0.277242</td>\n",
       "      <td>0.467668</td>\n",
       "      <td>-0.017484</td>\n",
       "      <td>-0.347959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291255</td>\n",
       "      <td>-0.326717</td>\n",
       "      <td>0.556356</td>\n",
       "      <td>0.270712</td>\n",
       "      <td>-0.243657</td>\n",
       "      <td>0.012702</td>\n",
       "      <td>-0.659360</td>\n",
       "      <td>-0.533906</td>\n",
       "      <td>-0.031788</td>\n",
       "      <td>-0.228691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.194242</td>\n",
       "      <td>0.421401</td>\n",
       "      <td>-0.654781</td>\n",
       "      <td>-0.400463</td>\n",
       "      <td>0.049589</td>\n",
       "      <td>-0.051367</td>\n",
       "      <td>0.312759</td>\n",
       "      <td>0.372741</td>\n",
       "      <td>-0.046611</td>\n",
       "      <td>0.288821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277609</td>\n",
       "      <td>-0.330695</td>\n",
       "      <td>-0.407934</td>\n",
       "      <td>-0.683901</td>\n",
       "      <td>0.122348</td>\n",
       "      <td>0.432768</td>\n",
       "      <td>-0.049903</td>\n",
       "      <td>0.131172</td>\n",
       "      <td>0.220528</td>\n",
       "      <td>0.374126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19419</th>\n",
       "      <td>-0.346381</td>\n",
       "      <td>-0.386836</td>\n",
       "      <td>-0.285172</td>\n",
       "      <td>-0.698478</td>\n",
       "      <td>0.363948</td>\n",
       "      <td>-0.154375</td>\n",
       "      <td>0.152917</td>\n",
       "      <td>0.032063</td>\n",
       "      <td>-0.548909</td>\n",
       "      <td>-0.286879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246428</td>\n",
       "      <td>-0.672198</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>-0.732471</td>\n",
       "      <td>0.292190</td>\n",
       "      <td>0.178698</td>\n",
       "      <td>-0.355341</td>\n",
       "      <td>0.699010</td>\n",
       "      <td>0.394960</td>\n",
       "      <td>0.282664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19420</th>\n",
       "      <td>-0.164353</td>\n",
       "      <td>-0.310164</td>\n",
       "      <td>-0.376411</td>\n",
       "      <td>0.057925</td>\n",
       "      <td>-0.283778</td>\n",
       "      <td>-0.888570</td>\n",
       "      <td>0.153458</td>\n",
       "      <td>0.605381</td>\n",
       "      <td>0.325039</td>\n",
       "      <td>-0.019916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382797</td>\n",
       "      <td>-0.424750</td>\n",
       "      <td>-0.046074</td>\n",
       "      <td>-0.277036</td>\n",
       "      <td>-0.334268</td>\n",
       "      <td>-0.287257</td>\n",
       "      <td>-0.204704</td>\n",
       "      <td>-0.287441</td>\n",
       "      <td>0.444298</td>\n",
       "      <td>0.329128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19421</th>\n",
       "      <td>0.195371</td>\n",
       "      <td>-0.142254</td>\n",
       "      <td>-0.558937</td>\n",
       "      <td>-0.708055</td>\n",
       "      <td>-0.130774</td>\n",
       "      <td>-0.034444</td>\n",
       "      <td>0.607338</td>\n",
       "      <td>0.239534</td>\n",
       "      <td>-0.114867</td>\n",
       "      <td>-0.529376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275973</td>\n",
       "      <td>-0.515575</td>\n",
       "      <td>-0.098523</td>\n",
       "      <td>-0.397691</td>\n",
       "      <td>-0.134628</td>\n",
       "      <td>-0.028014</td>\n",
       "      <td>0.207612</td>\n",
       "      <td>-0.145796</td>\n",
       "      <td>0.276164</td>\n",
       "      <td>0.154704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19422</th>\n",
       "      <td>-0.879802</td>\n",
       "      <td>-0.023629</td>\n",
       "      <td>-1.310903</td>\n",
       "      <td>-0.252232</td>\n",
       "      <td>0.043911</td>\n",
       "      <td>0.015211</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.556253</td>\n",
       "      <td>0.449734</td>\n",
       "      <td>-0.208044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.665855</td>\n",
       "      <td>-0.306281</td>\n",
       "      <td>-0.188037</td>\n",
       "      <td>-0.709096</td>\n",
       "      <td>-0.280147</td>\n",
       "      <td>0.375512</td>\n",
       "      <td>-0.521198</td>\n",
       "      <td>-0.028755</td>\n",
       "      <td>0.451886</td>\n",
       "      <td>0.215897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19423</th>\n",
       "      <td>-0.230175</td>\n",
       "      <td>-0.397699</td>\n",
       "      <td>-1.367513</td>\n",
       "      <td>-0.396495</td>\n",
       "      <td>-0.271280</td>\n",
       "      <td>0.067537</td>\n",
       "      <td>-0.043847</td>\n",
       "      <td>0.354488</td>\n",
       "      <td>-0.169875</td>\n",
       "      <td>0.069924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.564781</td>\n",
       "      <td>-0.301106</td>\n",
       "      <td>-0.287968</td>\n",
       "      <td>-0.856122</td>\n",
       "      <td>-0.102501</td>\n",
       "      <td>0.289302</td>\n",
       "      <td>-0.490340</td>\n",
       "      <td>0.571249</td>\n",
       "      <td>0.503205</td>\n",
       "      <td>0.310778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19424 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.060026  0.221741 -0.433798 -0.083594 -0.168791 -0.329348  0.331437   \n",
       "1     -0.417709  0.230312 -0.006228 -0.393662  0.010482 -0.102744  0.424900   \n",
       "2     -0.283884  0.192580 -0.870445 -0.476400 -0.394105  0.354576 -0.109303   \n",
       "3     -0.359992  0.444496 -0.386753 -0.415471 -0.221740  0.355020  0.277242   \n",
       "4     -0.194242  0.421401 -0.654781 -0.400463  0.049589 -0.051367  0.312759   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19419 -0.346381 -0.386836 -0.285172 -0.698478  0.363948 -0.154375  0.152917   \n",
       "19420 -0.164353 -0.310164 -0.376411  0.057925 -0.283778 -0.888570  0.153458   \n",
       "19421  0.195371 -0.142254 -0.558937 -0.708055 -0.130774 -0.034444  0.607338   \n",
       "19422 -0.879802 -0.023629 -1.310903 -0.252232  0.043911  0.015211  0.001198   \n",
       "19423 -0.230175 -0.397699 -1.367513 -0.396495 -0.271280  0.067537 -0.043847   \n",
       "\n",
       "              7         8         9  ...       758       759       760  \\\n",
       "0      0.270058  0.051187 -0.362599  ...  0.095292 -0.303023  0.074494   \n",
       "1      0.378988  0.259314 -0.420153  ... -0.043257 -0.230388  0.594411   \n",
       "2     -0.130869  0.137070 -0.577601  ...  0.077262 -0.424112  0.123815   \n",
       "3      0.467668 -0.017484 -0.347959  ...  0.291255 -0.326717  0.556356   \n",
       "4      0.372741 -0.046611  0.288821  ... -0.277609 -0.330695 -0.407934   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "19419  0.032063 -0.548909 -0.286879  ... -0.246428 -0.672198  0.004103   \n",
       "19420  0.605381  0.325039 -0.019916  ... -0.382797 -0.424750 -0.046074   \n",
       "19421  0.239534 -0.114867 -0.529376  ... -0.275973 -0.515575 -0.098523   \n",
       "19422  0.556253  0.449734 -0.208044  ... -0.665855 -0.306281 -0.188037   \n",
       "19423  0.354488 -0.169875  0.069924  ... -0.564781 -0.301106 -0.287968   \n",
       "\n",
       "            761       762       763       764       765       766       767  \n",
       "0     -0.489258 -0.217383  0.375361 -0.074646 -0.213903  0.598430 -0.047500  \n",
       "1     -0.459798  0.150881  0.059332 -0.446885 -0.145089  0.407795  0.438078  \n",
       "2     -0.916357  0.021797  0.347901 -0.310322 -0.152313  0.018452  0.146952  \n",
       "3      0.270712 -0.243657  0.012702 -0.659360 -0.533906 -0.031788 -0.228691  \n",
       "4     -0.683901  0.122348  0.432768 -0.049903  0.131172  0.220528  0.374126  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "19419 -0.732471  0.292190  0.178698 -0.355341  0.699010  0.394960  0.282664  \n",
       "19420 -0.277036 -0.334268 -0.287257 -0.204704 -0.287441  0.444298  0.329128  \n",
       "19421 -0.397691 -0.134628 -0.028014  0.207612 -0.145796  0.276164  0.154704  \n",
       "19422 -0.709096 -0.280147  0.375512 -0.521198 -0.028755  0.451886  0.215897  \n",
       "19423 -0.856122 -0.102501  0.289302 -0.490340  0.571249  0.503205  0.310778  \n",
       "\n",
       "[19424 rows x 768 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00816aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = pd.read_csv('df_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb93a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = df_validation.iloc[:, :768]\n",
    "Y_validation = df_validation.iloc[:, 768]\n",
    "gender_validation = df_validation.iloc[:, 769]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861fe2fc",
   "metadata": {},
   "source": [
    "# SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2312bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b3b94e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 21  2 ... 12 12  7]\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the training data\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "\n",
    "# Directly pass X_validation without wrapping it in an additional list\n",
    "prediction = sgd_clf.predict(X_validation)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16bc50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_scores, confusion_matrices_eval = gap_eval_scores(prediction, Y_validation, gender_validation, metrics=['TPR', 'FPR', 'PPR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18d64822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7210449583435714\n"
     ]
    }
   ],
   "source": [
    "final_score = (eval_scores['macro_fscore']+ (1-eval_scores['TPR_GAP']))/2\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0690eec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.6643655 ,  -7.21814703,  -6.28889128, ..., -14.59858921,\n",
       "         -6.48942323,  -8.29565462],\n",
       "       [-11.95869289,  -4.199551  , -11.07319655, ...,  -7.89718586,\n",
       "         -5.3481498 , -19.50637207],\n",
       "       [-12.36024134, -10.86185907,   1.06870236, ..., -10.20779592,\n",
       "        -14.18040761, -14.98092284],\n",
       "       ...,\n",
       "       [ -5.78586571,   0.49542962,  -5.61978555, ...,  -6.80242773,\n",
       "         -3.76815385, -11.01661692],\n",
       "       [-10.06916198, -11.9120879 , -11.31641832, ...,  -9.09061766,\n",
       "         -3.7681622 , -11.22620473],\n",
       "       [-10.48020585,  -7.71450638,  -8.46034911, ...,  -5.02193694,\n",
       "         -9.88222433, -22.15817715]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_scores = sgd_clf.decision_function(X_validation)\n",
    ">>> some_digit_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e2fee1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161910"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> np.argmax(some_digit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "137f609b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> sgd_clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271b4402",
   "metadata": {},
   "source": [
    "# OneVSoneClassifier or OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19c42dba",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=42))\n",
    ">>> ovo_clf.fit(X_train, Y_train)\n",
    ">>> prediction = ovo_clf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc85d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_scores, confusion_matrices_eval = gap_eval_scores(prediction, Y_validation, gender_validation, metrics=['TPR', 'FPR', 'PPR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7a993e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7195512287500783\n"
     ]
    }
   ],
   "source": [
    "final_score = (eval_scores['macro_fscore']+ (1-eval_scores['TPR_GAP']))/2\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3820284a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ovo_clf.estimators_)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3a1d9052",
   "metadata": {},
   "source": [
    "##### Nombre de classificateurs binaires différents : \n",
    "![image.png](attachment:image.png)\n",
    "N : 28 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e68dfcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création et entraînement du classificateur OneVsRest\n",
    "ovr_clf = OneVsRestClassifier(SGDClassifier(random_state=42))\n",
    "ovr_clf.fit(X_train, Y_train)\n",
    "\n",
    "# Prédiction sur le jeu de validation\n",
    "prediction = ovr_clf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9af74f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_scores, confusion_matrices_eval = gap_eval_scores(prediction, Y_validation, gender_validation, metrics=['TPR', 'FPR', 'PPR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1434a788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7184692644176063\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "final_score = (eval_scores['macro_fscore']+ (1-eval_scores['TPR_GAP']))/2\n",
    "print(final_score)\n",
    "print(len(ovr_clf.estimators_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e359b98",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93377c09",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a48d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cdfd4763",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> forest_clf.fit(X_train, Y_train)\n",
    ">>> prediction = forest_clf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8fc11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_scores, confusion_matrices_eval = gap_eval_scores(prediction, Y_validation, gender_validation, metrics=['TPR', 'FPR', 'PPR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c156048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6082560218460951\n"
     ]
    }
   ],
   "source": [
    "final_score = (eval_scores['macro_fscore']+ (1-eval_scores['TPR_GAP']))/2\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d711409d",
   "metadata": {},
   "source": [
    "# SGD_classifier avec CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7af06f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75370675, 0.73682043, 0.73599671, 0.75823723, 0.72281713,\n",
       "       0.74176277, 0.7446458 , 0.75617792])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sgd_clf, X_train, Y_train, cv=8, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ead689a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 21  2 ... 12 12  7]\n"
     ]
    }
   ],
   "source": [
    "# Directly pass X_validation without wrapping it in an additional list\n",
    "prediction = sgd_clf.predict(X_validation)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb522074",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_scores, confusion_matrices_eval = gap_eval_scores(prediction, Y_validation, gender_validation, metrics=['TPR', 'FPR', 'PPR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8594bbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7210449583435714\n"
     ]
    }
   ],
   "source": [
    "final_score = (eval_scores['macro_fscore'] + (1-eval_scores['TPR_GAP']))/2\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c7fc03",
   "metadata": {},
   "source": [
    "# Classifier naif de bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d32b038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49054587790568616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Instancier le classifieur Naive Bayes\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "nb_clf.fit(X_train, Y_train)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de validation\n",
    "prediction = nb_clf.predict(X_validation)\n",
    "\n",
    "# Évaluer les scores\n",
    "eval_scores, confusion_matrices_eval = gap_eval_scores(prediction, Y_validation, gender_validation, metrics=['TPR', 'FPR', 'PPR'])\n",
    "\n",
    "# Calculer le final_score\n",
    "final_score = (eval_scores['macro_fscore'] + (1 - eval_scores['TPR_GAP'])) / 2\n",
    "\n",
    "# Afficher le final_score\n",
    "print(final_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "be076688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48625507486211905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mita\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Transformer les données pour s'assurer que toutes les valeurs sont positives\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_validation_scaled = scaler.transform(X_validation)\n",
    "\n",
    "# Instancier le classifieur Naive Bayes pour des prédicteurs discrets\n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement transformées\n",
    "nb_clf.fit(X_train_scaled, Y_train)\n",
    "\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de validation\n",
    "prediction = nb_clf.predict(X_validation)\n",
    "\n",
    "# Évaluer les scores\n",
    "eval_scores, confusion_matrices_eval = gap_eval_scores(prediction, Y_validation, gender_validation, metrics=['TPR', 'FPR', 'PPR'])\n",
    "\n",
    "# Calculer le final_score\n",
    "final_score = (eval_scores['macro_fscore'] + (1 - eval_scores['TPR_GAP'])) / 2\n",
    "\n",
    "# Afficher le final_score\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ec893",
   "metadata": {},
   "source": [
    "# Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f4e576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.732370271149895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instancier le modèle de régression logistique\n",
    "logistic_clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Entraîner le modèle\n",
    "logistic_clf.fit(X_train, Y_train)\n",
    "\n",
    "# Faire des prédictions\n",
    "prediction = logistic_clf.predict(X_validation)\n",
    "\n",
    "# Évaluer les scores\n",
    "eval_scores, confusion_matrices_eval = gap_eval_scores(prediction, Y_validation, gender_validation, metrics=['TPR', 'FPR', 'PPR'])\n",
    "\n",
    "# Calculer le final_score\n",
    "final_score = (eval_scores['macro_fscore'] + (1 - eval_scores['TPR_GAP'])) / 2\n",
    "\n",
    "# Afficher le final_score\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128fa5d3",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "286e9fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7221981670503668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instancier le modèle SVM avec un noyau linéaire\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Entraîner le modèle\n",
    "svm_clf.fit(X_train, Y_train)\n",
    "\n",
    "# Faire des prédictions\n",
    "prediction = svm_clf.predict(X_validation)\n",
    "\n",
    "# Évaluer les scores\n",
    "eval_scores, confusion_matrices_eval = gap_eval_scores(prediction, Y_validation, gender_validation, metrics=['TPR', 'FPR', 'PPR'])\n",
    "\n",
    "# Calculer le final_score\n",
    "final_score = (eval_scores['macro_fscore'] + (1 - eval_scores['TPR_GAP'])) / 2\n",
    "\n",
    "# Afficher le final_score\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20666055",
   "metadata": {},
   "source": [
    "# Réseau de neuronnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f79ce1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/e4/14/d795bb156f8cc10eb1dcfe1332b7dbb8405b634688980aa9be8f885cc888/tensorflow-2.16.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow-2.16.1-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-intel==2.16.1 from https://files.pythonhosted.org/packages/e0/36/6278e4e7e69a90c00e0f82944d8f2713dd85a69d1add455d9e50446837ab/tensorflow_intel-2.16.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_intel-2.16.1-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for astunparse>=1.6.0 from https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.5.26 from https://files.pythonhosted.org/packages/bf/45/c961e3cb6ddad76b325c163d730562bb6deb1ace5acbed0306f5fbefb90e/flatbuffers-24.3.7-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-24.3.7-py2.py3-none-any.whl.metadata (849 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 from https://files.pythonhosted.org/packages/fa/39/5aae571e5a5f4de9c3445dae08a530498e5c53b0e74410eeeb0991c79047/gast-0.5.4-py3-none-any.whl.metadata\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for google-pasta>=0.1.1 from https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for h5py>=3.10.0 from https://files.pythonhosted.org/packages/b6/35/ed21094eb4d8acf31ccc7666a4d8701c1ce38f8d1fa3c7036f24416f6337/h5py-3.10.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading h5py-3.10.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/02/8c/dc970bc00867fe290e8c8a7befa1635af716a9ebdfe3fb9dce0ca4b522ce/libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes~=0.3.1 from https://files.pythonhosted.org/packages/a4/db/1784b87285588788170f87e987bfb4bda218d62a70a81ebb66c94e7f9b95/ml_dtypes-0.3.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for opt-einsum>=2.3.2 from https://files.pythonhosted.org/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl.metadata\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\mita\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/ad/6e/1bed3b7c904cc178cb8ee8dbaf72934964452b3de95b7a63412591edb93c/protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mita\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl.metadata\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/78/a9/eaa378e6fe421c2f61bdd4b92439b2b8bb320526f2b0e08fcf4e21c2f855/grpcio-1.62.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.62.1-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for tensorboard<2.17,>=2.16 from https://files.pythonhosted.org/packages/3a/d0/b97889ffa769e2d1fdebb632084d5e8b53fc299d43a537acee7ec0c021a3/tensorboard-2.16.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for keras>=3.0.0 from https://files.pythonhosted.org/packages/b0/b2/104733bb67fde86f3d10010f0b5c93cfa1d5bf552f904584cf9e5b3ba719/keras-3.0.5-py3-none-any.whl.metadata\n",
      "  Downloading keras-3.0.5-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/ac/4e/9566a313927be582ca99455a9523a097c7888fc819695bdc08415432b202/tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/87/67/a37f6214d0e9fe57f6ae54b2956d550ca8365857f42a1ce0392bb21d9410/rich-13.7.1-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for namex from https://files.pythonhosted.org/packages/cd/43/b971880e2eb45c0bee2093710ae8044764a89afe9620df34a231c6f0ecd2/namex-0.0.7-py3-none-any.whl.metadata\n",
      "  Downloading namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting dm-tree (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for dm-tree from https://files.pythonhosted.org/packages/e4/c1/522041457444b67125ac9527208bb3148f63d7dce0a86ffa589ec763a10e/dm_tree-0.1.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mita\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.16.1-cp311-cp311-win_amd64.whl (2.1 kB)\n",
      "Downloading tensorflow_intel-2.16.1-cp311-cp311-win_amd64.whl (377.0 MB)\n",
      "   ---------------------------------------- 0.0/377.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/377.0 MB 36.7 MB/s eta 0:00:11\n",
      "   ---------------------------------------- 3.1/377.0 MB 40.2 MB/s eta 0:00:10\n",
      "    --------------------------------------- 6.6/377.0 MB 52.8 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 10.7/377.0 MB 81.8 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 14.5/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 17.0/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 17.8/377.0 MB 65.2 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 21.5/377.0 MB 65.6 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 24.3/377.0 MB 59.5 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 26.7/377.0 MB 54.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 28.9/377.0 MB 65.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 31.3/377.0 MB 65.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 34.4/377.0 MB 59.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 38.4/377.0 MB 65.2 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 41.6/377.0 MB 81.8 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 45.9/377.0 MB 93.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 50.1/377.0 MB 93.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 52.6/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 55.5/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 58.6/377.0 MB 72.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 61.8/377.0 MB 72.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 65.9/377.0 MB 93.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 68.4/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 71.9/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 75.7/377.0 MB 72.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 79.4/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 83.4/377.0 MB 93.0 MB/s eta 0:00:04\n",
      "   --------- ----------------------------- 88.9/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   --------- ----------------------------- 92.6/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 93.9/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 96.3/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 99.6/377.0 MB 65.6 MB/s eta 0:00:05\n",
      "   ---------- ---------------------------- 102.3/377.0 MB 59.5 MB/s eta 0:00:05\n",
      "   ---------- ---------------------------- 105.3/377.0 MB 72.6 MB/s eta 0:00:04\n",
      "   ----------- --------------------------- 107.9/377.0 MB 72.6 MB/s eta 0:00:04\n",
      "   ----------- --------------------------- 111.7/377.0 MB 72.6 MB/s eta 0:00:04\n",
      "   ----------- --------------------------- 115.3/377.0 MB 72.6 MB/s eta 0:00:04\n",
      "   ------------ -------------------------- 118.6/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   ------------ -------------------------- 121.7/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   ------------ ------------------------- 126.7/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   ------------- ------------------------ 132.5/377.0 MB 131.2 MB/s eta 0:00:02\n",
      "   ------------- ------------------------ 137.2/377.0 MB 131.2 MB/s eta 0:00:02\n",
      "   -------------- ----------------------- 143.7/377.0 MB 131.2 MB/s eta 0:00:02\n",
      "   --------------- ---------------------- 148.8/377.0 MB 129.5 MB/s eta 0:00:02\n",
      "   --------------- ---------------------- 152.4/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   --------------- ---------------------- 158.1/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   ---------------- --------------------- 161.4/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   ----------------- --------------------- 165.3/377.0 MB 93.0 MB/s eta 0:00:03\n",
      "   ----------------- -------------------- 169.7/377.0 MB 131.2 MB/s eta 0:00:02\n",
      "   ----------------- -------------------- 174.3/377.0 MB 131.2 MB/s eta 0:00:02\n",
      "   ----------------- -------------------- 178.5/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   ------------------ ------------------- 183.2/377.0 MB 131.2 MB/s eta 0:00:02\n",
      "   ------------------ ------------------- 188.1/377.0 MB 110.0 MB/s eta 0:00:02\n",
      "   ------------------- ------------------ 192.8/377.0 MB 129.5 MB/s eta 0:00:02\n",
      "   ------------------- ------------------ 197.8/377.0 MB 131.2 MB/s eta 0:00:02\n",
      "   -------------------- ----------------- 202.6/377.0 MB 110.0 MB/s eta 0:00:02\n",
      "   --------------------- ---------------- 208.8/377.0 MB 131.2 MB/s eta 0:00:02\n",
      "   --------------------- ---------------- 213.6/377.0 MB 131.2 MB/s eta 0:00:02\n",
      "   ---------------------- --------------- 218.4/377.0 MB 131.2 MB/s eta 0:00:02\n",
      "   ---------------------- --------------- 223.4/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   ---------------------- --------------- 228.0/377.0 MB 131.2 MB/s eta 0:00:02\n",
      "   ----------------------- -------------- 233.0/377.0 MB 110.0 MB/s eta 0:00:02\n",
      "   ----------------------- -------------- 237.7/377.0 MB 129.5 MB/s eta 0:00:02\n",
      "   ------------------------ ------------- 242.3/377.0 MB 110.0 MB/s eta 0:00:02\n",
      "   ------------------------ ------------- 247.2/377.0 MB 110.0 MB/s eta 0:00:02\n",
      "   ------------------------- ------------ 250.5/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   ------------------------- ------------ 255.7/377.0 MB 110.0 MB/s eta 0:00:02\n",
      "   -------------------------- ----------- 260.1/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   -------------------------- ----------- 264.6/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 268.9/377.0 MB 93.9 MB/s eta 0:00:02\n",
      "   --------------------------- ---------- 272.8/377.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 276.9/377.0 MB 93.0 MB/s eta 0:00:02\n",
      "   ---------------------------- --------- 280.6/377.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 284.5/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 289.1/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   ----------------------------- -------- 294.2/377.0 MB 110.0 MB/s eta 0:00:01\n",
      "   ------------------------------ ------- 300.1/377.0 MB 162.4 MB/s eta 0:00:01\n",
      "   ------------------------------ ------- 304.6/377.0 MB 129.5 MB/s eta 0:00:01\n",
      "   ------------------------------- ------ 309.4/377.0 MB 110.0 MB/s eta 0:00:01\n",
      "   ------------------------------- ------ 314.8/377.0 MB 110.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ----- 320.3/377.0 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ----- 324.5/377.0 MB 131.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ---- 330.3/377.0 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ---- 334.9/377.0 MB 131.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- --- 338.9/377.0 MB 131.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- --- 344.3/377.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- -- 349.4/377.0 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 352.1/377.0 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ - 357.4/377.0 MB 110.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ - 361.2/377.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ - 366.5/377.0 MB 131.2 MB/s eta 0:00:01\n",
      "   -------------------------------------  370.3/377.0 MB 110.0 MB/s eta 0:00:01\n",
      "   -------------------------------------  374.7/377.0 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 377.0/377.0 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB ? eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.62.1-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------------------------------------  3.8/3.8 MB 121.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 80.4 MB/s eta 0:00:00\n",
      "Downloading h5py-3.10.0-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 85.9 MB/s eta 0:00:00\n",
      "Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 68.1 MB/s eta 0:00:00\n",
      "Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 5.5/24.4 MB 117.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 10.0/24.4 MB 105.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 13.6/24.4 MB 93.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 17.9/24.4 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.0/24.4 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 65.1 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.3.2-cp311-cp311-win_amd64.whl (127 kB)\n",
      "   ---------------------------------------- 0.0/127.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 127.7/127.7 kB ? eta 0:00:00\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 413.4/413.4 kB 25.2 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------  5.5/5.5 MB 171.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 87.0 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 92.3 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading dm_tree-0.1.8-cp311-cp311-win_amd64.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.3/101.3 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "   ---------------------------------------- 0.0/240.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 240.7/240.7 kB ? eta 0:00:00\n",
      "Installing collected packages: namex, libclang, flatbuffers, dm-tree, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.9.0\n",
      "    Uninstalling h5py-3.9.0:\n",
      "      Successfully uninstalled h5py-3.9.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 dm-tree-0.1.8 flatbuffers-24.3.7 gast-0.5.4 google-pasta-0.2.0 grpcio-1.62.1 h5py-3.10.0 keras-3.0.5 libclang-16.0.6 ml-dtypes-0.3.2 namex-0.0.7 opt-einsum-3.3.0 protobuf-4.25.3 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-intel-2.16.1 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "170d8648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mita\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0262 - loss: -2859.2527\n",
      "Epoch 2/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0238 - loss: -32580.5684\n",
      "Epoch 3/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968us/step - accuracy: 0.0271 - loss: -94152.0234\n",
      "Epoch 4/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.0274 - loss: -183453.6250\n",
      "Epoch 5/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0268 - loss: -294197.5312\n",
      "Epoch 6/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0256 - loss: -427895.5625\n",
      "Epoch 7/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 0.0259 - loss: -577371.6250\n",
      "Epoch 8/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0264 - loss: -742877.1250\n",
      "Epoch 9/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0271 - loss: -927781.0625\n",
      "Epoch 10/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.0267 - loss: -1133246.1250\n",
      "Epoch 11/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0274 - loss: -1347019.3750\n",
      "Epoch 12/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0275 - loss: -1592678.3750\n",
      "Epoch 13/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.0243 - loss: -1851472.8750\n",
      "Epoch 14/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0274 - loss: -2086782.2500\n",
      "Epoch 15/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0257 - loss: -2397989.7500\n",
      "Epoch 16/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 0.0274 - loss: -2689831.7500\n",
      "Epoch 17/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0259 - loss: -3019526.2500\n",
      "Epoch 18/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0251 - loss: -3328356.2500\n",
      "Epoch 19/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0272 - loss: -3699471.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0257 - loss: -4026125.2500\n",
      "Epoch 21/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0247 - loss: -4407613.5000\n",
      "Epoch 22/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0269 - loss: -4807709.0000\n",
      "Epoch 23/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0265 - loss: -5224441.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0265 - loss: -5599144.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0265 - loss: -6048160.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0246 - loss: -6550797.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0241 - loss: -6976093.5000\n",
      "Epoch 28/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0284 - loss: -7444814.5000\n",
      "Epoch 29/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 0.0255 - loss: -7951037.0000\n",
      "Epoch 30/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0249 - loss: -8468168.0000\n",
      "Epoch 31/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0248 - loss: -9003489.0000\n",
      "Epoch 32/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0258 - loss: -9544221.0000\n",
      "Epoch 33/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0270 - loss: -10152123.0000\n",
      "Epoch 34/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0267 - loss: -10655262.0000\n",
      "Epoch 35/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0274 - loss: -11247608.0000\n",
      "Epoch 36/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0264 - loss: -11805725.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0262 - loss: -12452365.0000\n",
      "Epoch 38/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0254 - loss: -13069033.0000\n",
      "Epoch 39/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0272 - loss: -13679042.0000\n",
      "Epoch 40/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0279 - loss: -14443474.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0257 - loss: -15210998.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0272 - loss: -15795151.0000\n",
      "Epoch 43/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0267 - loss: -16497620.0000\n",
      "Epoch 44/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0284 - loss: -17162286.0000\n",
      "Epoch 45/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0261 - loss: -17996254.0000\n",
      "Epoch 46/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0258 - loss: -18797454.0000\n",
      "Epoch 47/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 0.0277 - loss: -19516740.0000\n",
      "Epoch 48/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0249 - loss: -20327196.0000\n",
      "Epoch 49/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0243 - loss: -21045384.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0285 - loss: -21869328.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0262 - loss: -22799442.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0268 - loss: -23612692.0000\n",
      "Epoch 53/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0266 - loss: -24451790.0000\n",
      "Epoch 54/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0242 - loss: -25359946.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0240 - loss: -26110632.0000\n",
      "Epoch 56/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0264 - loss: -26938846.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0272 - loss: -27825390.0000\n",
      "Epoch 58/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0249 - loss: -29057170.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0239 - loss: -29958804.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0278 - loss: -30789296.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0263 - loss: -31870428.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0271 - loss: -32759610.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 0.0254 - loss: -33663092.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0253 - loss: -34861732.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0249 - loss: -36140900.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - accuracy: 0.0276 - loss: -36747536.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0289 - loss: -37990316.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0278 - loss: -39315368.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0255 - loss: -39954956.0000\n",
      "Epoch 70/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0263 - loss: -41256960.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 0.0250 - loss: -42488384.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0249 - loss: -43632396.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0251 - loss: -44737080.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 0.0281 - loss: -45585660.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0271 - loss: -47048840.0000\n",
      "Epoch 76/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0268 - loss: -48336940.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0263 - loss: -49351316.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0248 - loss: -50582092.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0276 - loss: -51773948.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0285 - loss: -53460380.0000\n",
      "Epoch 81/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0269 - loss: -54615156.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 0.0260 - loss: -55503324.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0265 - loss: -57280460.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0254 - loss: -58688760.0000\n",
      "Epoch 85/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0268 - loss: -59798224.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0283 - loss: -60765904.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0270 - loss: -61969980.0000\n",
      "Epoch 88/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0259 - loss: -63921432.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0264 - loss: -64800564.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0256 - loss: -66635832.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0243 - loss: -68170624.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0263 - loss: -68927272.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0257 - loss: -70867480.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0243 - loss: -72049648.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0265 - loss: -73963624.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0266 - loss: -75540168.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0274 - loss: -76778952.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0249 - loss: -77943352.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0255 - loss: -79840312.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0255 - loss: -81152072.0000\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "0.5008169516474186\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Définir le modèle de réseau de neurones\n",
    "nn_clf = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "nn_clf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "nn_clf.fit(X_train, Y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Faire des prédictions\n",
    "# Ici, vous devez seuiller la sortie pour obtenir des prédictions de classe binaires\n",
    "prediction = (nn_clf.predict(X_validation) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Évaluer les scores\n",
    "eval_scores, confusion_matrices_eval = gap_eval_scores(prediction, Y_validation, gender_validation, metrics=['TPR', 'FPR', 'PPR'])\n",
    "\n",
    "# Calculer le final_score\n",
    "final_score = (eval_scores['macro_fscore'] + (1 - eval_scores['TPR_GAP'])) / 2\n",
    "\n",
    "# Afficher le final_score\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316cfe8e",
   "metadata": {},
   "source": [
    "# arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "76b055af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5626324365510851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instancier le modèle d'arbre de décision\n",
    "decision_tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "decision_tree_clf.fit(X_train, Y_train)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de validation\n",
    "decision_tree_prediction = decision_tree_clf.predict(X_validation)\n",
    "\n",
    "# Évaluer les scores, en supposant que vous avez une fonction appropriée pour cela\n",
    "decision_tree_eval_scores, decision_tree_confusion_matrices_eval = gap_eval_scores(decision_tree_prediction, Y_validation, gender_validation, metrics=['TPR', 'FPR', 'PPR'])\n",
    "\n",
    "# Calculer le final_score\n",
    "decision_tree_final_score = (decision_tree_eval_scores['macro_fscore'] + (1 - decision_tree_eval_scores['TPR_GAP'])) / 2\n",
    "\n",
    "# Afficher le final_score\n",
    "print(decision_tree_final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a508772e",
   "metadata": {},
   "source": [
    "# Essaie d'implémentation d'une fonction pour exécuter tous les modèles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "47a18eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_model(model, X_train, Y_train, X_validation, Y_validation, gender_validation):\n",
    "    # Entraîner le modèle sur les données d'entraînement\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Faire des prédictions sur l'ensemble de validation\n",
    "    predictions = model.predict(X_validation)\n",
    "\n",
    "    # Évaluer les scores, en utilisant une fonction gap_eval_scores\n",
    "    eval_scores, confusion_matrices_eval = gap_eval_scores(predictions, Y_validation, gender_validation, metrics=['TPR', 'FPR', 'PPR'])\n",
    "\n",
    "    # Calculer le final_score\n",
    "    final_score = (eval_scores['macro_fscore'] + (1 - eval_scores['TPR_GAP'])) / 2\n",
    "    \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f4ae6763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score for Decision Tree Classifier: 0.5626324365510851\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation avec un arbre de décision\n",
    "decision_tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_final_score = evaluate_model(decision_tree_clf, X_train, Y_train, X_validation, Y_validation, gender_validation)\n",
    "print(f\"Final score for Decision Tree Classifier: {decision_tree_final_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cabb2a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score for Logistic Regression: 0.732370271149895\n",
      "Final score for SGD Classifier: 0.7210449583435714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Création d'une instance de LogisticRegression\n",
    "logistic_clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Évaluation du modèle de régression logistique\n",
    "logistic_final_score = evaluate_model(logistic_clf, X_train, Y_train, X_validation, Y_validation, gender_validation)\n",
    "print(f\"Final score for Logistic Regression: {logistic_final_score}\")\n",
    "\n",
    "# Création d'une instance de SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "# Évaluation du modèle SGDClassifier\n",
    "sgd_final_score = evaluate_model(sgd_clf, X_train, Y_train, X_validation, Y_validation, gender_validation)\n",
    "print(f\"Final score for SGD Classifier: {sgd_final_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
